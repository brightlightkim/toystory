from fastapi import APIRouter, File, UploadFile
from fastapi.responses import JSONResponse
# from src.controllers.yolo_model import detect_faces
# from src.controllers.deepface_model import analyze_emotion
# from src.controllers.image_processor import preprocess_image, crop_face
# from src.controllers.supabase_handler import fetch_latest_image_from_supabase
from src.controllers.openai_emotion_controller import openai_emotion_controller
import numpy as np
import cv2
import base64

emotion_router = APIRouter(prefix="/emotion")

WINDOW_SIZE = 10
DECAY_FACTOR = 0.8

@emotion_router.get("/analyze_robot/")
async def analyze_robot_image():
    # """
    # Bring the latest image from Supabase and analyze the emotion
    # """
    # contents = await fetch_latest_image_from_supabase()

    # if not contents:
    #     return JSONResponse(content={"emotion": "No image found", "happiness_score": 0})

    # img = preprocess_image(contents)

    # faces = detect_faces(img)
    # if not faces:
    #     return JSONResponse(content={"emotion": "No face detected", "happiness_score": 0})

    # face_img = crop_face(img, faces[0])
    # emotion_data = analyze_emotion(face_img)
    
    # if isinstance(emotion_data, list) and len(emotion_data) > 0:
    #     emotion_data = emotion_data[0]
    
    # emotion_scores = {key: float(value) for key, value in emotion_data.get("emotion", {}).items()}

    # current_happiness_score = (
    #     emotion_scores.get("happy", 0) * 2.0 +
    #     emotion_scores.get("neutral", 0) * 1.0 -
    #     emotion_scores.get("sad", 0) * 1.0 -
    #     emotion_scores.get("angry", 0) * 1.2 -
    #     emotion_scores.get("fear", 0) * 1.1
    # )

    # session_emotions = []
    # if session_emotions:
    #     prev_score = session_emotions[-1]
    #     happiness_score = DECAY_FACTOR * prev_score + (1 - DECAY_FACTOR) * current_happiness_score
    # else:
    #     happiness_score = current_happiness_score

    # session_emotions.append(happiness_score)
    # if len(session_emotions) > WINDOW_SIZE:
    #     session_emotions.pop(0)

    # smooth_happiness_score = sum(session_emotions) / len(session_emotions)

    # return JSONResponse(content={"emotion": emotion_data, "happiness_score": round(float(smooth_happiness_score), 2)})
    return JSONResponse(content={"emotion": "No image found", "happiness_score": 0})

@emotion_router.post("/analyze_webcam/")
async def analyze_webcam(image: UploadFile = File(...)):
    """
    Get the image from the webcam and analyze the emotion of the face
    """
    # contents = await image.read()
    # np_arr = np.frombuffer(contents, np.uint8)
    # img = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)

    # faces = detect_faces(img)
    # if not faces:
    #     return JSONResponse(content={"emotion": "No face detected", "happiness_score": 0})

    # face_img = crop_face(img, faces[0])  # ì²« ë²ˆì§¸ ì–¼êµ´ë§Œ ê°ì • ë¶„ì„
    # emotion_data = analyze_emotion(face_img)  # ê°ì • ë¶„ì„ ì‹¤í–‰
    
    # # ğŸ”¥ DeepFaceì˜ ë°˜í™˜ ë°ì´í„° êµ¬ì¡° ì²˜ë¦¬
    # if isinstance(emotion_data, list) and len(emotion_data) > 0:
    #     emotion_data = emotion_data[0]  # ë¦¬ìŠ¤íŠ¸ì¼ ê²½ìš° ì²« ë²ˆì§¸ ê²°ê³¼ ì‚¬ìš©
    
    # # ê°ì • ì ìˆ˜ ì¶”ì¶œ
    # emotion_scores = {key: float(value) for key, value in emotion_data.get("emotion", {}).items()}
    # # print("âœ… Emotion Scores:", emotion_scores)  # ë””ë²„ê¹…ìš© ë¡œê·¸

    # # ì£¼ìš” ê°ì • ê¸°ë°˜ í–‰ë³µì§€ìˆ˜ ê³„ì‚°
    # current_happiness_score = (
    #     emotion_scores.get("happy", 0) * 2.0 +   # í–‰ë³µí•œ ê°ì • ë¹„ì¤‘ â†‘
    #     emotion_scores.get("neutral", 0) * 1.0 - # ì¤‘ë¦½ ìœ ì§€
    #     emotion_scores.get("sad", 0) * 1.0 -     # ìŠ¬í”” ì˜í–¥ â†“
    #     emotion_scores.get("angry", 0) * 1.2 -   # ë¶„ë…¸ ì˜í–¥ â†“
    #     emotion_scores.get("fear", 0) * 1.1      # ë‘ë ¤ì›€ ì˜í–¥ â†“
    # )
    
    # session_emotions = []

    # if session_emotions:
    #     prev_score = session_emotions[-1]
    #     happiness_score = DECAY_FACTOR * prev_score + (1 - DECAY_FACTOR) * current_happiness_score
    # else:
    #     happiness_score = current_happiness_score

    # # ğŸ”¹ ìµœê·¼ 10ê°œ ê°’ìœ¼ë¡œ ì´ë™ í‰ê·  ì ìš© (ë³€ë™ì„± ìµœì†Œí™”)
    # session_emotions.append(happiness_score)
    # if len(session_emotions) > WINDOW_SIZE:
    #     session_emotions.pop(0)

    # smooth_happiness_score = sum(session_emotions) / len(session_emotions)


    # return JSONResponse(content={"emotion": emotion_data, "happiness_score": round(float(happiness_score), 2)})

    contents = await image.read()
    encoded_image = base64.b64encode(contents).decode('utf-8')

    emotion_data = await openai_emotion_controller(encoded_image)

    if isinstance(emotion_data, list) and len(emotion_data) > 0:
        emotion_data = emotion_data[0]

    # Extract the emotion and happiness score
    emotion = emotion_data.get("emotion", "neutral")
    happiness_score = float(emotion_data.get("happiness_score", 0))

    return JSONResponse(content={"emotion": emotion, "happiness_score": round(float(happiness_score), 2)})
    
    # return JSONResponse(content={"emotion": "No face detected", "happiness_score": 0})


@emotion_router.get("/happiness_score/")
async def get_happiness_score():
    """
    í˜„ì¬ê¹Œì§€ì˜ í‰ê·  í–‰ë³µì§€ìˆ˜ë¥¼ ë°˜í™˜í•˜ëŠ” API
    """
    
    session_emotions = []
    
    if not session_emotions:
        return JSONResponse(content={"happiness_score": 0})

    average_score = sum(session_emotions) / len(session_emotions)
    return JSONResponse(content={"happiness_score": round(float(average_score), 2)})